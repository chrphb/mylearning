{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is MyLearning Module\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime, date, time, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* json : JSON encoder and decoder - https://docs.python.org/3/library/json.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the core "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def say_hello(to):\n",
    "    \"Say Hello to somebody\"\n",
    "    return f'Hello {to}!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Christophe!'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "say_hello(\"Christophe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def special_parse(line, second_separator):\n",
    "    \"\"\"This is used for raw parsing of a text file, created manually \n",
    "    from a pdf file with a list of chinese words.\n",
    "    It returns a dictionnary with hanzi, pinyin, and fr.\n",
    "    \"\"\"\n",
    "    s1 = line.find(\" \")\n",
    "    rest = line[s1+1:]\n",
    "    s2 = rest.find(second_separator)\n",
    "    h = line[:s1]\n",
    "    p = rest[0:s2]\n",
    "    f = rest[s2+1:]\n",
    "    return {\"hanzi\":h,\"pinyin\":p,\"fr\":f.strip()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def initial_load():\n",
    "    \"\"\"Initial load of the raw text file\"\"\"\n",
    "    print(\"start\")\n",
    "    total = 0\n",
    "    terms = []\n",
    "    with open(\"/home/chris/brain/1-projects/python-hsk2/data/raw.txt\",'r')  as reader:\n",
    "        for line in reader.readlines():\n",
    "            # skip the lines 'Juin 2010'\n",
    "            if(line.find(\"Juin\")==-1):\n",
    "                # find the first space\n",
    "                s = line.find(' ')\n",
    "                notraditional = line[s+1:]\n",
    "                #print(line,end='')\n",
    "                #print(notraditional, end='')\n",
    "                if(line.find(\"#\")!=-1):\n",
    "                    r = special_parse(notraditional, \"#\")\n",
    "                    print(r)\n",
    "                    terms.append(r) \n",
    "                else:\n",
    "                    r = special_parse(notraditional, \" \")\n",
    "                    print(r)\n",
    "                    terms.append(r)\n",
    "                total = total + 1\n",
    "        print(\"ok\")\n",
    "    #print(terms)\n",
    "    print(\"end\")\n",
    "    print(\"out of\",total)\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def create_study_plan(terms):\n",
    "    \"\"\"Create the initial study plan\"\"\"\n",
    "    STUDYMAX = 30\n",
    "    revised = []\n",
    "    count = 0\n",
    "    mydate = datetime.today()\n",
    "    for term in terms:\n",
    "        count += 1 \n",
    "        if(count%STUDYMAX==0):\n",
    "            mydate += timedelta(days=1)\n",
    "        t = mydate.strftime('%Y-%m-%d')\n",
    "        #print(\"add\",t)\n",
    "        term[\"study\"] = t\n",
    "        revised.append(term)\n",
    "    return revised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def export_json(terms):\n",
    "    with open(\"/home/chris/brain/1-projects/python-hsk2/data/study.json\",'w')  as writer:\n",
    "        json.dump(terms, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def import_json():\n",
    "    \"\"\"Import the JSON back\"\"\"\n",
    "    with open(\"/home/chris/brain/1-projects/python-hsk2/data/study.json\",'r')  as reader:\n",
    "        data = json.load(reader)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def with_next_study_date(term,input):\n",
    "    \"\"\"Trivial learning algorithm: if there is an error: \n",
    "    we keep at the same day (no progress, will be asked the next time),\n",
    "    if this is OK, then today+3 days\"\"\"\n",
    "    mydate = datetime.today()\n",
    "    if(input!=\"w\"):\n",
    "        mydate += timedelta(days=3)\n",
    "        t = mydate.strftime('%Y-%m-%d')\n",
    "        term[\"study\"]=t\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def play(terms):\n",
    "    \"\"\"Main Play Loop\"\"\"\n",
    "    print(\"Let's play !!!!!!!!! (q to quit)\")\n",
    "    mydate = datetime.today().strftime('%Y-%m-%d')\n",
    "    study_revised = []\n",
    "    quit = False\n",
    "    todo = 0\n",
    "    for term in terms:\n",
    "        date_time_obj = datetime.strptime(term[\"study\"], '%Y-%m-%d')\n",
    "        if(quit==False and date_time_obj <= datetime.today()):\n",
    "            todo += 1\n",
    "    counter = 1\n",
    "    for term in terms:\n",
    "        date_time_obj = datetime.strptime(term[\"study\"], '%Y-%m-%d')\n",
    "        if(quit==False and date_time_obj <= datetime.today()):\n",
    "            print(counter, \"/\", todo, \": \", term[\"hanzi\"], term[\"pinyin\"], \"?\")  \n",
    "            counter += 1 \n",
    "            c=input(\"...\")  \n",
    "            if(c==\"q\"):\n",
    "                quit = True\n",
    "            else:\n",
    "                print(term[\"fr\"])\n",
    "                c=input(\"...\")  \n",
    "                term = with_next_study_date(term,c)\n",
    "                #print(term)\n",
    "        study_revised.append(term)\n",
    "    print(\"Well Done !!!!\")\n",
    "    return study_revised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start... 1 to init, 2 to play\n",
      "2\n",
      "Let's play !!!!!!!!! (q to quit)\n",
      "Well Done !!!!\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "print(\"Start... 1 to init, 2 to play\")\n",
    "select = input()\n",
    "if(select==\"1\"):\n",
    "    terms = initial_load()\n",
    "    revised = create_study_plan(terms)\n",
    "    #print(revised)\n",
    "    export_json(revised)\n",
    "if(select==\"2\"):\n",
    "    data = import_json()\n",
    "    #print(data)\n",
    "    study = play(data)\n",
    "    export_json(study)\n",
    "print(\"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try some string manipulations\n",
    "\n",
    "Note that the string below have a u prefix : u indicates unicode string (whatever the encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hanzi': '还可以', 'pinyin': 'Hái kěyǐ', 'fr': 'acceptable'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = u\"还可以\"\n",
    "p = u\"Hái kěyǐ\"\n",
    "f = u\"acceptable\"\n",
    "myjson = {\"hanzi\":h,\"pinyin\":p,\"fr\":f}\n",
    "myjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"hanzi\": \"\\\\u8fd8\\\\u53ef\\\\u4ee5\", \"pinyin\": \"H\\\\u00e1i k\\\\u011by\\\\u01d0\", \"fr\": \"acceptable\"}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(myjson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Asserts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert say_hello(\"Christophe\")==\"Hello Christophe!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
